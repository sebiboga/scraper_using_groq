name: Run GroqCloud Crawler with curl

on:
  workflow_dispatch:
    inputs:
      start_url:
        description: 'Starting URL domain'
        required: true
        type: string
        default: 'https://farmec.ro'
      model:
        description: 'Select the model to use'
        required: true
        type: choice
        options:
          - compound-beta
          - compound-beta-mini
          - llama-3.3-70b-versatile
        default: compound-beta

jobs:
  crawl_career_page:
    runs-on: ubuntu-latest

    steps:
      - name: Call GroqCloud API with system and user prompts
        id: call_api
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          START_URL: ${{ github.event.inputs.start_url }}
          MODEL: ${{ github.event.inputs.model }}
        run: |
          SYSTEM_PROMPT="act like a smart crawler better than apache nutch; the crawling will start from a starting url that user is providing; first just identify the career page and print it out. no explanation needed. print this out as JSON and key to be career_page and put also the company in JSON. check for links in footer.  look for career page link. this is the most important part. no explanation needed new"

          USER_PROMPT="Starting URL: $START_URL . Respond *only* with the JSON object, no explanations, no extra text."

          # Compose JSON payload with both system and user messages
          PAYLOAD=$(jq -n --arg model "$MODEL" --arg sys "$SYSTEM_PROMPT" --arg user "$USER_PROMPT" '{
            model: $model,
            messages: [
              {role: "system", content: $sys},
              {role: "user", content: $user}
            ]
          }')

         

          RESPONSE=$(curl -s -X POST https://api.groq.com/openai/v1/chat/completions \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $GROQ_API_KEY" \
            -d "$PAYLOAD")

          echo "Full response:"
          echo "$RESPONSE"

          # Extract the content field
          CONTENT=$(echo "$RESPONSE" | jq -r '.choices[0].message.content')

          echo "Extracted content:"
          echo "$CONTENT"
          CAREER_PAGE=$(echo "$CONTENT" | jq -r '.career_page')
          echo "career_page=$CAREER_PAGE" >> $GITHUB_OUTPUT
          
  crawl_job_links:
   runs-on: ubuntu-latest
   needs: crawl_career_page
   steps:
    - name: Call GroqCloud API to crawl job links from career page
      id: call_job_links
      env:
        GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        CAREER_PAGE: ${{ needs.crawl_career_page.outputs.career_page }}
        MODEL: ${{ github.event.inputs.model }}
      run: |
        SYSTEM_PROMPT="act like a smart crawler like apache nutch; print out all urls you find in this page. do a crawl level 1; do not print out duplicates. filter those that have higher probability to be a job description pages; output as a JSON file with key job_link and company"
        USER_PROMPT="Starting URL: https://www.farmec.ro/compania/cariere/ . Respond *only* with the JSON object, no explanations, no extra text."

        PAYLOAD=$(jq -n --arg model "$MODEL" --arg sys "$SYSTEM_PROMPT" --arg user "$USER_PROMPT" '{
          model: $model,
          messages: [
            {role: "system", content: $sys},
            {role: "user", content: $user}
          ]
        }')

        RESPONSE=$(curl -s -X POST https://api.groq.com/openai/v1/chat/completions \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer $GROQ_API_KEY" \
          -d "$PAYLOAD")

         CONTENT=$(echo "$RESPONSE" | jq -r '.choices[0].message.content')

          echo "Raw content:"
          echo "$CONTENT"

          # Extract JSON from code block if present
          JOB_LINKS=$(echo "$CONTENT" | sed -n '/```

          # If the model returns only [], this will work; if it's empty, fallback to []
          if [ -z "$JOB_LINKS" ]; then
            JOB_LINKS="[]"
          fi

          echo "Extracted job links JSON:"
          echo "$JOB_LINKS"

          # Set output only if it's valid JSON
          echo "job_links=$JOB_LINKS" >> $GITHUB_OUTPUT
          

    
